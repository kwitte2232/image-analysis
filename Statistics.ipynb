{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n",
      "True\n",
      "True\n",
      "NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/scipy/stats/mstats_basic.py:2231: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=15\n",
      "  np.min(n))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "x = np.array([1, 2, 3, -1, 5, 7, 3, 7]) #The array needs to be larger than 20, just an example\n",
    "z,pval = scipy.stats.mstats.normaltest(x)\n",
    "\n",
    "if(pval < 0.05):\n",
    "    print \"Not normal distribution\"\n",
    "else:\n",
    "    print \"Normal\"\n",
    "    \n",
    "bem1_dir = '/Users/Kristen/Desktop/12132016/PULSED_POLARIZATION/WYK8308_Pulsed_Polarization/WYK8308_10sec_Pol'\n",
    "cdc24_dir = '/Users/Kristen/Desktop/12132016/PULSED_POLARIZATION/WYK8440_Pulsed_Polarization/WYK8440_10sec_Pol'\n",
    "    \n",
    "def extract_values(curr_dir):\n",
    "    for f in os.listdir(curr_dir):\n",
    "        if f == \"Mean_Polarization_Intensities.csv\":\n",
    "            current_file = os.path.join(curr_dir, f)\n",
    "            data = pd.read_csv(current_file)\n",
    "            ten_min_slice = data.loc[[30],:]\n",
    "            ten_min_slice.drop('SEM', axis=1, inplace=True)\n",
    "            ten_min_slice.drop('Final Ave', axis=1, inplace=True)\n",
    "            ten_min_slice.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            measurements = np.asarray(ten_min_slice)\n",
    "    return measurements\n",
    "\n",
    "def is_normal(pval):\n",
    "    \n",
    "    if(pval < 0.05):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "bem_measurements = extract_values(bem1_dir)\n",
    "bem_Z, bem_pval = scipy.stats.mstats.normaltest(bem_measurements[0])\n",
    "bem_normality = is_normal(bem_pval)\n",
    "print bem_normality\n",
    "\n",
    "cdc24_measurements = extract_values(cdc24_dir)\n",
    "cdc24_Z, cdc24_pval = scipy.stats.mstats.normaltest(cdc24_measurements[0])\n",
    "cdc24_normality = is_normal(cdc24_pval)\n",
    "print cdc24_normality\n",
    "\n",
    "if cdc24_normality and bem_normality:\n",
    "    t,prob = scipy.stats.ttest_ind(bem_measurements[0], cdc24_measurements[0])\n",
    "    #print t, prob\n",
    "    if prob > 0.05:\n",
    "        print \"NS\"\n",
    "    else:\n",
    "        print \"Statistically Significant\"\n",
    "else:\n",
    "    stat, pvalue = scipy.stats.mannwhitneyu(bem_measurements[0], cdc24_measurements[0])\n",
    "    if pvalue > 0.05:\n",
    "        print \"NS\"\n",
    "    else:\n",
    "        print \"Statistically Significant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996712805118 0.0157765052967\n",
      "1.0029732812 0.0553611745013\n",
      "(71, 1)\n",
      "(47, 1)\n",
      "0.0131668980901\n",
      "Statistically Significant\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "one = '/Users/Kristen/Documents/Images/Old_Desktop/PositiveFeedback_Data/Figure1_Done/PULSED_POLARIZATION/WYK8308_Pulsed_Polarization/WYK8308_Control_Pol'\n",
    "two = '/Users/Kristen/Documents/Images/Old_Desktop/PositiveFeedback_Data/Figure1_Done/PULSED_POLARIZATION/WYK8308_Pulsed_Polarization/WYK8308_Control_Pol'\n",
    "\n",
    "def extract_values_polarized(curr_dir):\n",
    "    for f in os.listdir(curr_dir):\n",
    "        if f == \"Mean_Small_Bud_Intensities.csv\" or f == \"Mean_Intensities_NEW_2.csv\":\n",
    "            current_file = os.path.join(curr_dir, f)\n",
    "            data = pd.read_csv(current_file)\n",
    "            ten_min_slice = data.loc[[10],:]\n",
    "            ten_min_slice.drop('SEM', axis=1, inplace=True)\n",
    "            ten_min_slice.drop('Final Ave', axis=1, inplace=True)\n",
    "            ten_min_slice.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            measurements = np.asarray(ten_min_slice)\n",
    "            median = np.median(measurements)\n",
    "            std = np.std(measurements)\n",
    "            print median, std\n",
    "    return measurements\n",
    "\n",
    "def extract_values_nonPolarized(curr_dir):\n",
    "    for f in os.listdir(curr_dir):\n",
    "        if f == \"Mean_Polarization_Intensities.csv\" or f == \"Mean_Polarization_NEW_Intensities.csv\":\n",
    "            current_file = os.path.join(curr_dir, f)\n",
    "            data = pd.read_csv(current_file)\n",
    "            ten_min_slice = data.loc[[30],:]\n",
    "            ten_min_slice.drop('SEM', axis=1, inplace=True)\n",
    "            ten_min_slice.drop('Final Ave', axis=1, inplace=True)\n",
    "            ten_min_slice.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "            measurements = np.asarray(ten_min_slice)\n",
    "            median = np.median(measurements)\n",
    "            std = np.std(measurements)\n",
    "            print median, std\n",
    "    return measurements\n",
    "\n",
    "def extract_pol_values(curr_dir):\n",
    "    for f in os.listdir(curr_dir):\n",
    "        if f == \"Polarization_Efficiency.csv\" or f == \"new_bud_vs_target.csv\":\n",
    "            current_file = os.path.join(curr_dir, f)\n",
    "            data = pd.read_csv(current_file)\n",
    "            pol_eff = data[\"Pol_Eff\"]\n",
    "            measurements = np.asarray(pol_eff)\n",
    "            median = np.median(measurements)\n",
    "            std = np.std(measurements)\n",
    "            print median, std\n",
    "    return measurements\n",
    "\n",
    "def pol_values(current_file, column):\n",
    "\n",
    "    data = pd.read_csv(current_file)\n",
    "    pol_eff = data[column]\n",
    "    median = data[column].median()\n",
    "    std = data[column].std()\n",
    "    print column, median, std\n",
    "    measurements = np.asarray(pol_eff)\n",
    "    return measurements\n",
    "\n",
    "#first_measurements = np.transpose(pol_values(one, \"-25\"))\n",
    "#second_measurements = np.transpose(pol_values(two, \"-15\"))\n",
    "\n",
    "first_measurements = np.transpose(extract_values_polarized(one))\n",
    "second_measurements = np.transpose(extract_values_nonPolarized(two))\n",
    "\n",
    "print first_measurements.shape\n",
    "print second_measurements.shape\n",
    "\n",
    "stat, pvalue = scipy.stats.mannwhitneyu(first_measurements, second_measurements)\n",
    "print pvalue\n",
    "if pvalue > 0.05:\n",
    "    print \"NS\"\n",
    "else:\n",
    "    print \"Statistically Significant\"\n",
    "    \n",
    "#print \"Pol Eff\"\n",
    "#first_measurements = np.transpose(extract_pol_values(one))\n",
    "#second_measurements = np.transpose(extract_pol_values(two))\n",
    "\n",
    "#print first_measurements.shape\n",
    "#print second_measurements.shape\n",
    "\n",
    "#stat, pvalue = scipy.stats.mannwhitneyu(first_measurements, second_measurements)\n",
    "#print pvalue\n",
    "#if pvalue > 0.05:\n",
    "    #print \"NS\"\n",
    "#else:\n",
    "    #print \"Statistically Significant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/24_G1 24/42_G1S\n",
      "0.000286634930779\n",
      "Statistically Significant\n",
      "\n",
      "\n",
      "42/24_G1 42/24_G1S\n",
      "0.00267261569322\n",
      "Statistically Significant\n",
      "\n",
      "\n",
      "42/24_G1 24/42_G1\n",
      "0.0725353372091\n",
      "NS\n",
      "\n",
      "\n",
      "24/42_G1S 42/24_G1\n",
      "0.000286634930779\n",
      "Statistically Significant\n",
      "\n",
      "\n",
      "24/42_G1S 42/24_G1S\n",
      "0.145058593019\n",
      "NS\n",
      "\n",
      "\n",
      "24/42_G1S 24/42_G1\n",
      "0.00570832962283\n",
      "Statistically Significant\n",
      "\n",
      "\n",
      "42/24_G1S 42/24_G1\n",
      "0.00267261569322\n",
      "Statistically Significant\n",
      "\n",
      "\n",
      "42/24_G1S 24/42_G1S\n",
      "0.425678850221\n",
      "NS\n",
      "\n",
      "\n",
      "42/24_G1S 24/42_G1\n",
      "0.0304863189165\n",
      "Statistically Significant\n",
      "\n",
      "\n",
      "24/42_G1 42/24_G1\n",
      "0.0725353372091\n",
      "NS\n",
      "\n",
      "\n",
      "24/42_G1 24/42_G1S\n",
      "0.00570832962283\n",
      "Statistically Significant\n",
      "\n",
      "\n",
      "24/42_G1 42/24_G1S\n",
      "0.0304863189165\n",
      "Statistically Significant\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "paired = '/Users/Kristen/Desktop/PositiveFeedback_Data/Figure4_Done/PAIRED_LOCAL/Paired_Local.csv'\n",
    "\n",
    "def extract_pol_values(curr_dir, name):\n",
    "    for f in os.listdir(curr_dir):\n",
    "        if f == \"Stopped_CSV.csv\":\n",
    "            current_file = os.path.join(curr_dir, f)\n",
    "            data = pd.read_csv(current_file)\n",
    "            pol_eff = data[name]\n",
    "            measurements = np.asarray(pol_eff)\n",
    "            return measurements\n",
    "        \n",
    "def extract_values(df, name):\n",
    "    values = df[name]\n",
    "    measurements = np.asarray(values)\n",
    "    return measurements\n",
    "\n",
    "def get_data(curr_file):\n",
    "    data = pd.read_csv(curr_file)\n",
    "    columns = data.columns.values.tolist()\n",
    "    return data, columns\n",
    "\n",
    "data, columns = get_data(paired)\n",
    "\n",
    "all_data = {}\n",
    "for col in columns:\n",
    "    curr_data = extract_values(data, col)\n",
    "    all_data[col] = curr_data\n",
    "            \n",
    "all_data.keys()\n",
    "\n",
    "col_names = ['42/24_G1S','24/Bem1_G1','42/Bem1_G1','Bem1/24_G1','Bem1/42_G1S','24/42_G1S','42/Bem1_G1S','42/24_G1',\n",
    "             '24/Bem1_G1S','24/42_G1','Bem1/42_G1','Bem1/24_G1S']\n",
    "\n",
    "bem1_42 = ['42/Bem1_G1', 'Bem1/42_G1S', '42/Bem1_G1S', 'Bem1/42_G1']\n",
    "bem1_24 = ['24/Bem1_G1', 'Bem1/24_G1S', '24/Bem1_G1S', 'Bem1/24_G1']\n",
    "cdc42_24 = ['42/24_G1', '24/42_G1S', '42/24_G1S', '24/42_G1']\n",
    "\n",
    "for label in cdc42_24:\n",
    "    for comp in cdc42_24:\n",
    "        if label != comp:\n",
    "            stat, pvalue = scipy.stats.mannwhitneyu(all_data[label], all_data[comp])\n",
    "            ci = stats.norm.interval(0.95, loc=mu, scale=sigma/sqrt(N))\n",
    "            print label, comp\n",
    "            print pvalue\n",
    "            if pvalue > 0.05:\n",
    "                print \"NS\"\n",
    "                print \"\\n\"\n",
    "            else:\n",
    "                print \"Statistically Significant\"\n",
    "                print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.500000</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0.222222</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1  2\n",
       "0  1  0.500000  1\n",
       "1  1  0.222222  1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame([[1,2,3], [1,2,3]])\n",
    "df2 = pd.DataFrame([[1,4,3], [1,9,3]])\n",
    "\n",
    "new_df = df.div(df2)\n",
    "new_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_aves(df, type_data):\n",
    "\n",
    "    one = type_data+\"_ROI_0\"\n",
    "    two = type_data+\"_ROI_1\"\n",
    "    three = type_data+\"_ROI_2\"\n",
    "    data = df[[one, two, three]]\n",
    "    data['ave'] = data.mean(axis=1)\n",
    "    data['sem'] = data.std(axis=1)/math.sqrt(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
